"""
Telegram Bot –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–π–¥–∂–µ–π —Å Nonabana
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç —Ç–µ–∫—Å—Ç ‚Üí –±–æ—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º reference images
"""

import os
import logging
import requests
import tempfile
import math
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
import replicate
from replicate.exceptions import ReplicateError
from deep_translator import GoogleTranslator
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
    ConversationHandler
)
from dotenv import load_dotenv
import numpy as np

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# =============================================================================

# API –¢–æ–∫–µ–Ω—ã
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "YOUR_TELEGRAM_BOT_TOKEN")
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN", "YOUR_REPLICATE_TOKEN")

# –ú–æ–¥–µ–ª–∏ Replicate
GENERATION_MODEL = "google/nano-banana"
GENERATION_SEED = None  # None = —Å–ª—É—á–∞–π–Ω—ã–π, —á–∏—Å–ª–æ = —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed
BACKGROUND_REMOVAL_MODEL = "851-labs/background-remover:a029dff38972b5fda4ec5d75d7d1cd25aeff621d2cf4946a41055d7db66b80bc"
BACKGROUND_REMOVAL_ENABLED = False  # –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ

# –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
GENERATE_TEXT_IN_PROMPT = True  # True = —Ç–µ–∫—Å—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç–µ, False = –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ

# –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
REFERENCE_IMAGES_DIR = "reference_images"
USE_PREDEFINED_REFERENCE_IMAGES = True
FEMALE_REFERENCE_IMAGE = "Girl.jpg"  # –†–µ—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è –∂–µ–Ω—Å–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∂–µ–Ω—Å–∫–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
FEMALE_KEYWORDS = [
    'girl', 'woman', 'female', 'lady', 'she', 'her', 'wife', 'mother', 'mom', 'daughter',
    '–¥–µ–≤—É—à–∫–∞', '–∂–µ–Ω—â–∏–Ω–∞', '–¥–µ–≤–æ—á–∫–∞', '–¥–∞–º–∞', '–∂–µ–Ω–∞', '–º–∞—Ç—å', '–º–∞–º–∞', '–¥–æ—á—å', '–¥–æ—á–∫–∞',
    '—Å–µ—Å—Ç—Ä–∞', 'sister', '–±–∞–±—É—à–∫–∞', 'grandmother', '—Ç—ë—Ç—è', 'aunt'
]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –±–µ–π–¥–∂–µ
FONT_PATH = "fonts/Golos-Text_Bold.ttf"
FONT_SIZE_BASE = 80
FONT_SIZE_MIN = 60
FONT_SIZE_MAX = 100
TEXT_COLOR = "#000000"
TEXT_BEND_SHORT = 20  # –ò–∑–≥–∏–± –¥–ª—è —Ç–µ–∫—Å—Ç–∞ <= 12 —Å–∏–º–≤–æ–ª–æ–≤
TEXT_BEND_LONG = 28   # –ò–∑–≥–∏–± –¥–ª—è —Ç–µ–∫—Å—Ç–∞ > 12 —Å–∏–º–≤–æ–ª–æ–≤
TEXT_VERTICAL_OFFSET = 6  # –°–º–µ—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤–≤–µ—Ä—Ö (–ø–∏–∫—Å–µ–ª–∏)
TEXT_LETTER_SPACING = 0.02  # –†–∞–∑—Ä—è–¥–∫–∞ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
TEXT_MAX_LENGTH = 20  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞ –±–∞–Ω–Ω–µ—Ä–∞
BANNER_SEARCH_AREA_START = 0.6  # –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ —Å 60% –≤—ã—Å–æ—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
BANNER_DEFAULT_Y_POSITION = 0.93  # –ü–æ–∑–∏—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (93% –æ—Ç –≤—ã—Å–æ—Ç—ã)
BANNER_YELLOW_LOWER = [200, 160, 40]   # RGB –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –∂—ë–ª—Ç–æ–≥–æ
BANNER_YELLOW_UPPER = [255, 220, 100]  # RGB –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –∂—ë–ª—Ç–æ–≥–æ

# –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
MESSAGES = {
    "start": """üëã –ü—Ä–∏–≤–µ—Ç, {name}!

–Ø —Å–æ–∑–¥–∞—é –±–µ–π–¥–∂–∏ —Å —Å–∞–º—É—Ä–∞–µ–º –≤ —Ç–≤–æ—ë–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–º —Å—Ç–∏–ª–µ.

üé® **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
1. –û–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å —Å–∞–º—É—Ä–∞–µ–º
   –ù–∞–ø—Ä–∏–º–µ—Ä: "—Å –≥–∏—Ç–∞—Ä–æ–π, —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π, –≤ –±–æ–µ–≤–æ–π —Å—Ç–æ–π–∫–µ —Å –º–µ—á–æ–º, —Å –º–æ–ª–æ—Ç–∫–æ–º, –≤ –æ–≤–µ—á—å–µ–π —à–∫—É—Ä–µ"
2. –£–∫–∞–∂–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –±–∞–Ω–Ω–µ—Ä–∞ –Ω–∞ –±–µ–π–¥–∂–µ, –Ω–µ –±–æ–ª–µ–µ 12 —Å–∏–º–≤–æ–ª–æ–≤
   –ù–∞–ø—Ä–∏–º–µ—Ä: "DEBUG NINJA", "CODE MASTER"
3. –ü–æ–ª—É—á–∏ –≥–æ—Ç–æ–≤—ã–π –±–µ–π–¥–∂!

–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å, –∏ –Ω–∞—á–Ω—ë–º! üöÄ

–ö–æ–º–∞–Ω–¥—ã:
/create - –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –±–µ–π–¥–∂
/help - –ü–æ–º–æ—â—å
/examples - –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤""",

    "help": """üìñ **–°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é**

–û–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å —Å–∞–º—É—Ä–∞–µ–º
‚Ä¢ –ù–∞–ø—Ä–∏–º–µ—Ä: "—Å –≥–∏—Ç–∞—Ä–æ–π, —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π, –≤ –±–æ–µ–≤–æ–π —Å—Ç–æ–π–∫–µ —Å –º–µ—á–æ–º, —Å –º–æ–ª–æ—Ç–∫–æ–º, –≤ –æ–≤–µ—á—å–µ–π —à–∫—É—Ä–µ"
‚Ä¢ –ú–æ–∂–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
‚Ä¢ –û–ø–∏—à–∏ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ

–£–∫–∞–∂–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –±–∞–Ω–Ω–µ—Ä–∞
‚Ä¢ –î–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–∏–¥–∞
‚Ä¢ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã —Å–º–æ—Ç—Ä—è—Ç—Å—è –ª—É—á—à–µ
‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã: "UX SCOUT", "DEBUG NINJA"

‚è± –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç 10-30 —Å–µ–∫—É–Ω–¥

üí° –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è, –ø—Ä–æ—Å—Ç–æ –Ω–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ!""",

    "examples": """üí° **–ü—Ä–∏–º–µ—Ä—ã —Ö–æ—Ä–æ—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:**

**–î–ª—è —Å—é–∂–µ—Ç–∞:**
‚úÖ "—Å–∞–º—É—Ä–∞–π –≤ –±–æ–µ–≤–æ–π —Å—Ç–æ–π–∫–µ —Å –º–µ—á–æ–º"
‚úÖ "—Å–∞–º—É—Ä–∞–π —Å –ª—É–Ω–æ–π –Ω–∞ —Ñ–æ–Ω–µ"
‚úÖ "—Å–∞–º—É—Ä–∞–π –≤ –¥–æ—Å–ø–µ—Ö–∞—Ö —Å –∫–∞—Ç–∞–Ω–æ–π"
‚úÖ "—Å–∞–º—É—Ä–∞–π –≤ –º–µ–¥–∏—Ç–∞—Ü–∏–∏"
‚úÖ "—Å–∞–º—É—Ä–∞–π –Ω–∞ —Ñ–æ–Ω–µ –≥–æ—Ä"
‚úÖ "—Å–∞–º—É—Ä–∞–π —Å –¥—Ä–∞–∫–æ–Ω–æ–º"

**–î–ª—è —Ç–µ–∫—Å—Ç–∞ –±–∞–Ω–Ω–µ—Ä–∞:**
‚úÖ "CODE SAMURAI"
‚úÖ "UX NINJA"
‚úÖ "DEBUG MASTER"
‚úÖ "API WARRIOR"
‚úÖ "DATA SENSEI"

‚ùå **–ò–∑–±–µ–≥–∞–π—Ç–µ:**
- –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Å—é–∂–µ—Ç–∞
- –î–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã: "THE BEST DEVELOPER IN THE WORLD\"""",

    "cancel": "‚ùå –°–æ–∑–¥–∞–Ω–∏–µ –±–µ–π–¥–∂–∞ –æ—Ç–º–µ–Ω–µ–Ω–æ.\n–ò—Å–ø–æ–ª—å–∑—É–π /create —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ!",

    "create_start": """üé® –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –±–µ–π–¥–∂!

–û–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ —á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å —Å–∞–º—É—Ä–∞–µ–º
–ù–∞–ø—Ä–∏–º–µ—Ä: "—Å –≥–∏—Ç–∞—Ä–æ–π, —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π, –≤ –±–æ–µ–≤–æ–π —Å—Ç–æ–π–∫–µ —Å –º–µ—á–æ–º, —Å –º–æ–ª–æ—Ç–∫–æ–º, –≤ –æ–≤–µ—á—å–µ–π —à–∫—É—Ä–µ"

–ò–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã""",

    "scene_received": """‚úÖ –û—Ç–ª–∏—á–Ω–æ! –°—é–∂–µ—Ç: *{scene}*

üì∏ –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ ({count} —à—Ç.)

–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?
–ù–∞–ø—Ä–∏–º–µ—Ä: DEBUG NINJA, CODE MASTER, UX SCOUT...

(–î–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤)""",

    "scene_received_no_refs": """‚úÖ –û—Ç–ª–∏—á–Ω–æ! –°—é–∂–µ—Ç: *{scene}*

‚ö†Ô∏è –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ {ref_dir}

–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?
–ù–∞–ø—Ä–∏–º–µ—Ä: DEBUG NINJA, CODE MASTER, UX SCOUT...

(–î–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤)""",

    "scene_received_old_mode": """‚úÖ –û—Ç–ª–∏—á–Ω–æ! –°—é–∂–µ—Ç: *{scene}*

–•–æ—á–µ—à—å –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ? (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
–û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ /skip —á—Ç–æ–±—ã –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å

–ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–æ 4 —Ñ–æ—Ç–æ""",

    "photo_uploaded_max": """‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {count} —Ñ–æ—Ç–æ (–º–∞–∫—Å–∏–º—É–º)

–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?
–ù–∞–ø—Ä–∏–º–µ—Ä: DEBUG NINJA, CODE MASTER, UX SCOUT...

(–î–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤)""",

    "photo_uploaded": """‚úÖ –§–æ—Ç–æ {count}/4 –∑–∞–≥—Ä—É–∂–µ–Ω–æ

–û—Ç–ø—Ä–∞–≤—å –µ—â—ë —Ñ–æ—Ç–æ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ /skip —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ —Ç–µ–∫—Å—Ç—É –±–∞–Ω–Ω–µ—Ä–∞""",

    "photo_error": "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π /skip",

    "skip_photos": """‚è≠ –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ

–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?
–ù–∞–ø—Ä–∏–º–µ—Ä: DEBUG NINJA, CODE MASTER, UX SCOUT...

(–î–æ {max_length} —Å–∏–º–≤–æ–ª–æ–≤)""",

    "text_too_long": """‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å–∏–º—É–º {max_length} —Å–∏–º–≤–æ–ª–æ–≤).
–ü–æ–ø—Ä–æ–±—É–π –ø–æ–∫–æ—Ä–æ—á–µ:""",

    "generating": "‚è≥ –°–æ–∑–¥–∞—é —Ç–≤–æ–π –±–µ–π–¥–∂...\n–≠—Ç–æ –∑–∞–π–º—ë—Ç 10-30 —Å–µ–∫—É–Ω–¥ ‚ö°",
    "generating_quick": "‚è≥ –°–æ–∑–¥–∞—é –±–µ–π–¥–∂...",

    "badge_ready": """üéä –¢–≤–æ–π –±–µ–π–¥–∂ –≥–æ—Ç–æ–≤!

üé® –°—é–∂–µ—Ç: {scene}
üìù –¢–µ–∫—Å—Ç: {text}

–•–æ—á–µ—à—å –µ—â—ë? –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ /create""",

    "badge_ready_quick": "üéä –ì–æ—Ç–æ–≤–æ!\n{scene} | {text}",

    "errors": {
        "model_not_found": """‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞

–ú–æ–¥–µ–ª—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ Replicate –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.
–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É GENERATION_MODEL –≤ –∫–æ–¥–µ –±–æ—Ç–∞.""",

        "auth_error": """‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å REPLICATE_API_TOKEN.""",

        "rate_limit": """‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤

–ü–æ–¥–æ–∂–¥–∏—Ç–µ –º–∏–Ω—É—Ç—É –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.""",

        "generic": """‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±–µ–π–¥–∂–∞.
–ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á–µ—Ä–µ–∑ /create

–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è, –ø–æ–ø—Ä–æ–±—É–π:
‚Ä¢ –£–ø—Ä–æ—Å—Ç–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—Ç
‚Ä¢ –ü–æ–¥–æ–∂–¥–∞—Ç—å –º–∏–Ω—É—Ç—É –∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞""",

        "generic_quick": "‚ùå –û—à–∏–±–∫–∞: {detail}\n\n–ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π /create"
    }
}

# –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
WAITING_FOR_SCENE, WAITING_FOR_BADGE_TEXT, WAITING_FOR_REFERENCE_PHOTOS = range(3)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò
# =============================================================================

def find_yellow_banner_center(img: Image.Image, user_id: int) -> tuple:
    """–ù–∞—Ö–æ–¥–∏—Ç —Ü–µ–Ω—Ç—Ä –∂—ë–ª—Ç–æ–≥–æ –±–∞–Ω–Ω–µ—Ä–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ —Ü–≤–µ—Ç—É"""
    try:
        img_array = np.array(img)
        height = img_array.shape[0]
        width = img_array.shape[1]
        search_area = img_array[int(height * BANNER_SEARCH_AREA_START):, :]
        
        if search_area.shape[-1] == 4:
            search_area = search_area[:, :, :3]
        
        lower_yellow = np.array(BANNER_YELLOW_LOWER)
        upper_yellow = np.array(BANNER_YELLOW_UPPER)
        mask = np.all((search_area >= lower_yellow) & (search_area <= upper_yellow), axis=-1)
        yellow_pixels = np.where(mask)
        
        if len(yellow_pixels[0]) > 0:
            center_y = int(np.mean(yellow_pixels[0])) + int(height * BANNER_SEARCH_AREA_START)
            center_x = int(np.mean(yellow_pixels[1]))
            logger.info(f"User {user_id}: Found yellow banner at ({center_x}, {center_y})")
            return (center_x, center_y)
        else:
            logger.warning(f"User {user_id}: Yellow banner not found, using default position")
            return (width // 2, int(height * BANNER_DEFAULT_Y_POSITION))
    except Exception as e:
        logger.error(f"User {user_id}: Error finding yellow banner: {e}")
        return (img.width // 2, int(img.height * BANNER_DEFAULT_Y_POSITION))


def is_female_prompt(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∂–µ–Ω—Å–∫–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞"""
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in FEMALE_KEYWORDS)


# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ–π/–¥–∏–Ω–∞–º–∏—á–Ω–æ–π —Å—Ü–µ–Ω—ã
ACTION_KEYWORDS = [
    'fight', 'fighting', 'battle', 'attack', 'sword', 'katana', 'strike', 'slash', 'jump', 'run',
    '–±–æ–π', '–±–∏—Ç–≤–∞', '–∞—Ç–∞–∫–∞', '–º–µ—á', '–∫–∞—Ç–∞–Ω–∞', '—É–¥–∞—Ä', '–ø—Ä—ã–∂–æ–∫', '–±–µ–∂–∞—Ç—å', '—Å—Ä–∞–∂–µ–Ω–∏–µ', '—Ä—É–±–∏—Ç',
    'combat', 'warrior', 'action', 'dynamic', 'stance', '–±–æ–µ–≤–æ–π', '—Å—Ç–æ–π–∫–∞', '–≤–æ–∏–Ω'
]


def is_action_scene(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ü–µ–Ω–∞ –∞–∫—Ç–∏–≤–Ω–æ–π/–¥–∏–Ω–∞–º–∏—á–Ω–æ–π"""
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in ACTION_KEYWORDS)


def load_single_reference_image(filename: str) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π —Ñ–∞–π–ª"""
    filepath = os.path.join(REFERENCE_IMAGES_DIR, filename)
    if not os.path.exists(filepath):
        logger.warning(f"Reference image {filepath} does not exist")
        return []
    
    try:
        with open(filepath, 'rb') as f:
            img_bytes = BytesIO(f.read())
            img_bytes.seek(0)
            logger.info(f"Loaded single reference image: {filename}")
            return [img_bytes]
    except Exception as e:
        logger.warning(f"Failed to load {filename}: {e}")
        return []


def load_reference_images_for_prompt(prompt: str) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
    if is_female_prompt(prompt):
        logger.info(f"Detected female character in prompt, using {FEMALE_REFERENCE_IMAGE}")
        return load_single_reference_image(FEMALE_REFERENCE_IMAGE)
    else:
        return load_reference_images_from_dir(REFERENCE_IMAGES_DIR)


def load_reference_images_from_dir(directory: str) -> list:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏, –∏—Å–∫–ª—é—á–∞—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã"""
    reference_images = []
    
    if not os.path.exists(directory):
        logger.warning(f"Directory {directory} does not exist")
        return reference_images
    
    supported_formats = ('.jpg', '.jpeg', '.png', '.webp', '.gif')
    excluded_files = [FEMALE_REFERENCE_IMAGE.lower()]
    
    try:
        files = [f for f in os.listdir(directory) 
                if os.path.isfile(os.path.join(directory, f)) 
                and f.lower().endswith(supported_formats)
                and f.lower() not in excluded_files]
        files.sort()
        
        for filename in files:
            filepath = os.path.join(directory, filename)
            try:
                with open(filepath, 'rb') as f:
                    img_bytes = BytesIO(f.read())
                    img_bytes.seek(0)
                    reference_images.append(img_bytes)
                    logger.info(f"Loaded reference image: {filename}")
            except Exception as e:
                logger.warning(f"Failed to load {filename}: {e}")
        
        logger.info(f"Loaded {len(reference_images)} reference image(s) from {directory}")
    except Exception as e:
        logger.error(f"Error loading reference images: {e}")
    
    return reference_images


def translate_to_english(text: str, user_id: int) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π"""
    try:
        has_cyrillic = any('\u0400' <= char <= '\u04FF' for char in text)
        if has_cyrillic:
            logger.info(f"User {user_id}: Translating '{text}' from Russian to English")
            translator = GoogleTranslator(source='ru', target='en')
            translated = translator.translate(text)
            logger.info(f"User {user_id}: Translated to '{translated}'")
            return translated
        return text
    except Exception as e:
        logger.warning(f"User {user_id}: Translation failed: {e}")
        return text


def generate_image_with_lora(scene_description: str, user_id: int, reference_images: list = None, badge_text: str = None) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å google/nano-banana"""
    if not os.getenv("REPLICATE_API_TOKEN"):
        os.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_TOKEN
    
    try:
        logger.info(f"User {user_id}: Generating image with scene '{scene_description}'")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å—Ü–µ–Ω—ã
        is_action = is_action_scene(scene_description)
        pose_prompt = "standing dynamic pose, waist-up shot" if is_action else "sitting in lotus pose, calm meditative"
        logger.info(f"User {user_id}: Scene type: {'action' if is_action else 'calm'}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
        is_female = is_female_prompt(scene_description)
        gender_prompt = "female samurai woman" if is_female else "male samurai man"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        prompt_parts = [
            f"single {gender_prompt}",
            pose_prompt,
            "upper body only",
            scene_description,
            "anatomically correct two hands only",
            "if holding sword then single katana held with both hands",
            "large red circle behind the character with white diagonal scratch marks across it",
            "red sun with white claw scratches",
            "plain light grey background",
            "isolated character",
            "centered composition",
            "solo character",
            "Japanese samurai style",
            "clean minimal background",
            "vector art style",
            "flat illustration"
        ]
        
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –ø—Ä–æ–º–ø—Ç–µ –∏ —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥–∞–Ω
        if GENERATE_TEXT_IN_PROMPT and badge_text:
            badge_text_upper = badge_text.upper()
            prompt_parts.append(f"bold black text '{badge_text_upper}' at the bottom, no background behind text")
            logger.info(f"User {user_id}: Including badge text '{badge_text_upper}' in prompt")
        else:
            prompt_parts.append("space for text at the bottom")
        
        prompt = ", ".join(prompt_parts)
        
        # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á—ë—Ç–æ–º –ø–æ–ª–∞
        negative_gender = "male, man, masculine" if is_female else "female, woman, feminine, girl"
        
        nano_banana_input = {
            "prompt": prompt,
            "negative_prompt": f"{negative_gender}, multiple people, crowd, full body, legs visible, standing full figure, background scenery, landscape, buildings, complex background, group photo, many characters, detailed background, other people, extras, text errors, misspelled words, wrong text, realistic photo, 3d render, yellow banner, text banner, text background, ribbon, badge, label behind text, colored background behind text, extra hands, extra arms, three hands, four hands, multiple hands, deformed hands, mutated hands, extra fingers, missing fingers, fused fingers, bad anatomy, multiple swords, two swords, dual wield, extra weapons, sword on back",
            "output_format": "jpg",
        }
        
        if reference_images:
            image_inputs = []
            for ref_image in reference_images:
                if isinstance(ref_image, BytesIO):
                    ref_image.seek(0)
                    image_inputs.append(ref_image)
                else:
                    image_inputs.append(ref_image)
            
            if image_inputs:
                nano_banana_input["image_input"] = image_inputs
                nano_banana_input["aspect_ratio"] = "match_input_image"
                logger.info(f"User {user_id}: Added {len(image_inputs)} reference image(s)")
        
        if GENERATION_SEED is not None:
            nano_banana_input["seed"] = int(GENERATION_SEED)
        
        output = replicate.run(GENERATION_MODEL, input=nano_banana_input)
        
        if hasattr(output, 'url'):
            image_url = output.url()
        else:
            image_url = output[0] if isinstance(output, list) else output
        
        logger.info(f"User {user_id}: Image generated successfully")
        return image_url
        
    except ReplicateError as e:
        error_detail = str(e)
        logger.error(f"User {user_id}: ReplicateError: {error_detail}")
        
        if "404" in error_detail or "not found" in error_detail.lower():
            error_msg = (
                f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (404)\n\n"
                f"–ú–æ–¥–µ–ª—å '{GENERATION_MODEL}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ Replicate.\n\n"
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞: https://replicate.com/{GENERATION_MODEL.split(':')[0]}"
            )
        else:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ Replicate API: {error_detail}"
        
        raise ValueError(error_msg) from e
    except Exception as e:
        logger.error(f"User {user_id}: Error generating image: {e}")
        raise


def remove_background(image_bytes: BytesIO, user_id: int) -> BytesIO:
    """–£–¥–∞–ª—è–µ—Ç —Ñ–æ–Ω —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Replicate API"""
    if not BACKGROUND_REMOVAL_ENABLED:
        image_bytes.seek(0)
        return image_bytes
    
    try:
        logger.info(f"User {user_id}: Removing background")
        
        if not os.getenv("REPLICATE_API_TOKEN"):
            os.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_TOKEN
        
        image_bytes.seek(0)
        img = Image.open(image_bytes)
        
        if img.mode == 'RGBA':
            background = Image.new('RGB', img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[3])
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')
        
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
            img.save(temp_file, format='PNG', quality=95)
            temp_file_path = temp_file.name
        
        try:
            with open(temp_file_path, 'rb') as img_file:
                output = replicate.run(
                    BACKGROUND_REMOVAL_MODEL,
                    input={
                        "image": img_file,
                        "format": "png",
                        "reverse": False,
                        "threshold": 0,
                        "background_type": "rgba"
                    }
                )
            
            if hasattr(output, 'read'):
                result_bytes = BytesIO(output.read())
                result_bytes.seek(0)
                return result_bytes
            elif hasattr(output, 'url'):
                image_url = output.url()
                response = requests.get(image_url)
                response.raise_for_status()
                result_bytes = BytesIO(response.content)
                result_bytes.seek(0)
                return result_bytes
            elif isinstance(output, (list, tuple)) and len(output) > 0:
                image_url = output[0]
                response = requests.get(image_url)
                response.raise_for_status()
                result_bytes = BytesIO(response.content)
                result_bytes.seek(0)
                return result_bytes
            else:
                image_url = str(output)
                if image_url.startswith('http'):
                    response = requests.get(image_url)
                    response.raise_for_status()
                    result_bytes = BytesIO(response.content)
                    result_bytes.seek(0)
                    return result_bytes
                raise ValueError(f"Unexpected output format: {type(output)}")
        finally:
            try:
                os.unlink(temp_file_path)
            except Exception as e:
                logger.warning(f"User {user_id}: Failed to delete temp file: {e}")
    except Exception as e:
        logger.error(f"User {user_id}: Error removing background: {e}")
        image_bytes.seek(0)
        return image_bytes


def add_text_to_badge(image_url: str, badge_text: str, user_id: int) -> BytesIO:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –±–∞–Ω–Ω–µ—Ä –±–µ–π–¥–∂–∞"""
    try:
        logger.info(f"User {user_id}: Adding text '{badge_text}' to badge")
        
        response = requests.get(image_url)
        response.raise_for_status()
        img = Image.open(BytesIO(response.content))
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img = img.convert('RGBA')
        
        draw = ImageDraw.Draw(img)
        badge_text = badge_text.upper()
        
        image_width = img.width
        scale_factor = image_width / 1024
        font_size = int(FONT_SIZE_BASE * scale_factor)
        font_size = max(FONT_SIZE_MIN, min(font_size, FONT_SIZE_MAX))
        
        font = None
        try:
            font = ImageFont.truetype(FONT_PATH, font_size)
        except Exception:
            try:
                font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", font_size)
            except Exception:
                font = ImageFont.load_default()
        
        if font is None:
            raise ValueError("Failed to load any font")
        
        banner_center_x, banner_center_y = find_yellow_banner_center(img, user_id)
        
        bend_amount = TEXT_BEND_SHORT if len(badge_text) <= 12 else TEXT_BEND_LONG
        
        char_widths = []
        total_width = 0
        for char in badge_text:
            char_bbox = draw.textbbox((0, 0), char, font=font)
            char_width = char_bbox[2] - char_bbox[0]
            char_widths.append(char_width)
            total_width += char_width * (1 + TEXT_LETTER_SPACING)
        
        total_width -= char_widths[-1] * TEXT_LETTER_SPACING
        start_x = banner_center_x - total_width / 2
        
        current_x = start_x
        for i, char in enumerate(badge_text):
            char_width = char_widths[i]
            relative_pos = (current_x + char_width/2 - banner_center_x) / (total_width / 2)
            y_offset = bend_amount * (relative_pos ** 2)
            
            draw.text(
                (current_x, banner_center_y - y_offset - TEXT_VERTICAL_OFFSET),
                char,
                font=font,
                fill=TEXT_COLOR,
                anchor="lt"
            )
            
            current_x += char_width * (1 + TEXT_LETTER_SPACING)
        
        output = BytesIO()
        img.save(output, format='PNG', quality=95)
        output.seek(0)
        
        logger.info(f"User {user_id}: Badge completed successfully")
        return output
        
    except Exception as e:
        logger.error(f"User {user_id}: Error adding text to badge: {e}")
        raise


# =============================================================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î
# =============================================================================

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user = update.effective_user
    await update.message.reply_text(MESSAGES["start"].format(name=user.first_name))
    return WAITING_FOR_SCENE


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
    await update.message.reply_text(MESSAGES["help"].format(max_length=TEXT_MAX_LENGTH))


async def examples_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /examples"""
    await update.message.reply_text(MESSAGES["examples"])


async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /cancel"""
    await update.message.reply_text(MESSAGES["cancel"])
    context.user_data.clear()
    return ConversationHandler.END


async def create_badge(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –±–µ–π–¥–∂–∞"""
    await update.message.reply_text(MESSAGES["create_start"])
    return WAITING_FOR_SCENE


async def handle_scene_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è —Å—é–∂–µ—Ç–∞"""
    user_id = update.effective_user.id
    scene_description = update.message.text.strip()
    scene_description_en = translate_to_english(scene_description, user_id)
    
    context.user_data['scene'] = scene_description_en
    context.user_data['scene_original'] = scene_description
    
    display_text = scene_description if scene_description == scene_description_en else f"{scene_description} ({scene_description_en})"
    
    if USE_PREDEFINED_REFERENCE_IMAGES:
        reference_images = load_reference_images_for_prompt(scene_description_en)
        context.user_data['reference_images'] = reference_images
        
        if reference_images:
            await update.message.reply_text(
                MESSAGES["scene_received"].format(
                    scene=display_text,
                    count=len(reference_images),
                    max_length=TEXT_MAX_LENGTH
                ),
                parse_mode='Markdown'
            )
        else:
            await update.message.reply_text(
                MESSAGES["scene_received_no_refs"].format(
                    scene=display_text,
                    ref_dir=REFERENCE_IMAGES_DIR,
                    max_length=TEXT_MAX_LENGTH
                ),
                parse_mode='Markdown'
            )
        return WAITING_FOR_BADGE_TEXT
    else:
        await update.message.reply_text(
            MESSAGES["scene_received_old_mode"].format(scene=display_text),
            parse_mode='Markdown'
        )
        context.user_data['reference_images'] = []
        return WAITING_FOR_REFERENCE_PHOTOS


async def handle_reference_photos(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö —Ñ–æ—Ç–æ"""
    if update.message.photo:
        photo = update.message.photo[-1]
        file = await context.bot.get_file(photo.file_id)
        
        photo_bytes = BytesIO()
        await file.download_to_memory(photo_bytes)
        photo_bytes.seek(0)
        
        if 'reference_images' not in context.user_data:
            context.user_data['reference_images'] = []
        
        context.user_data['reference_images'].append(photo_bytes)
        count = len(context.user_data['reference_images'])
        
        if count >= 4:
            await update.message.reply_text(
                MESSAGES["photo_uploaded_max"].format(count=count, max_length=TEXT_MAX_LENGTH),
                parse_mode='Markdown'
            )
            return WAITING_FOR_BADGE_TEXT
        else:
            await update.message.reply_text(MESSAGES["photo_uploaded"].format(count=count))
            return WAITING_FOR_REFERENCE_PHOTOS
    else:
        await update.message.reply_text(MESSAGES["photo_error"])
        return WAITING_FOR_REFERENCE_PHOTOS


async def skip_reference_photos(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö —Ñ–æ—Ç–æ"""
    await update.message.reply_text(
        MESSAGES["skip_photos"].format(max_length=TEXT_MAX_LENGTH),
        parse_mode='Markdown'
    )
    return WAITING_FOR_BADGE_TEXT


async def handle_badge_text_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –±–∞–Ω–Ω–µ—Ä–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–µ–π–¥–∂–∞"""
    user_id = update.effective_user.id
    badge_text = update.message.text.strip()
    
    if len(badge_text) > TEXT_MAX_LENGTH:
        await update.message.reply_text(
            MESSAGES["text_too_long"].format(max_length=TEXT_MAX_LENGTH)
        )
        return WAITING_FOR_BADGE_TEXT
    
    scene_description = context.user_data.get('scene', 'unknown scene')
    reference_images = context.user_data.get('reference_images', [])
    
    status_message = await update.message.reply_text(MESSAGES["generating"])
    
    try:
        # –ü–µ—Ä–µ–¥–∞—ë–º —Ç–µ–∫—Å—Ç –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –ø—Ä–æ–º–ø—Ç–µ
        image_url = generate_image_with_lora(
            scene_description, 
            user_id, 
            reference_images,
            badge_text=badge_text if GENERATE_TEXT_IN_PROMPT else None
        )
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–∞–ø –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        if GENERATE_TEXT_IN_PROMPT:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é
            response = requests.get(image_url)
            response.raise_for_status()
            image_with_text = BytesIO(response.content)
            image_with_text.seek(0)
        else:
            image_with_text = add_text_to_badge(image_url, badge_text, user_id)
        
        if BACKGROUND_REMOVAL_ENABLED:
            image_with_text = remove_background(image_with_text, user_id)
        
        await status_message.delete()
        
        original_scene = context.user_data.get('scene_original', scene_description)
        caption = MESSAGES["badge_ready"].format(scene=original_scene, text=badge_text)
        
        await update.message.reply_photo(photo=image_with_text, caption=caption)
        logger.info(f"User {user_id}: Badge created successfully")
        
    except ValueError as e:
        error_msg = str(e)
        logger.error(f"User {user_id}: Configuration error: {error_msg}")
        await status_message.edit_text(error_msg)
    except Exception as e:
        logger.error(f"User {user_id}: Failed to create badge: {e}")
        error_detail = str(e)
        
        if "404" in error_detail or "not found" in error_detail.lower():
            user_message = MESSAGES["errors"]["model_not_found"]
        elif "401" in error_detail or "unauthorized" in error_detail.lower():
            user_message = MESSAGES["errors"]["auth_error"]
        elif "429" in error_detail or "rate limit" in error_detail.lower():
            user_message = MESSAGES["errors"]["rate_limit"]
        else:
            user_message = MESSAGES["errors"]["generic"]
        
        await status_message.edit_text(user_message)
    
    context.user_data.clear()
    return ConversationHandler.END


async def handle_quick_generate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
    user_id = update.effective_user.id
    message_text = update.message.text.strip()
    
    if '|' in message_text:
        parts = message_text.split('|')
        scene_description = parts[0].strip()
        badge_text = parts[1].strip() if len(parts) > 1 else "SAMURAI"
        scene_description_en = translate_to_english(scene_description, user_id)
    else:
        scene_description_en = translate_to_english(message_text, user_id)
        context.user_data['scene'] = scene_description_en
        context.user_data['scene_original'] = message_text
        
        display_text = message_text if message_text == scene_description_en else f"{message_text} ({scene_description_en})"
        
        if USE_PREDEFINED_REFERENCE_IMAGES:
            reference_images = load_reference_images_for_prompt(scene_description_en)
            context.user_data['reference_images'] = reference_images
            
            if reference_images:
                await update.message.reply_text(
                    f"‚úÖ –°—é–∂–µ—Ç: *{display_text}*\n\n"
                    f"üì∏ –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ ({len(reference_images)} —à—Ç.)\n\n"
                    f"–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?",
                    parse_mode='Markdown'
                )
            else:
                await update.message.reply_text(
                    f"‚úÖ –°—é–∂–µ—Ç: *{display_text}*\n\n"
                    f"‚ö†Ô∏è –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n\n"
                    f"–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?",
                    parse_mode='Markdown'
                )
        else:
            await update.message.reply_text(
                f"‚úÖ –°—é–∂–µ—Ç: *{display_text}*\n\n"
                f"–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞—Ç—å –Ω–∞ –±–∞–Ω–Ω–µ—Ä–µ?",
                parse_mode='Markdown'
            )
        
        return WAITING_FOR_BADGE_TEXT
    
    status_message = await update.message.reply_text(MESSAGES["generating_quick"])
    
    reference_images = []
    if USE_PREDEFINED_REFERENCE_IMAGES:
        reference_images = load_reference_images_for_prompt(scene_description_en)
    
    try:
        # –ü–µ—Ä–µ–¥–∞—ë–º —Ç–µ–∫—Å—Ç –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –ø—Ä–æ–º–ø—Ç–µ
        image_url = generate_image_with_lora(
            scene_description_en, 
            user_id, 
            reference_images,
            badge_text=badge_text if GENERATE_TEXT_IN_PROMPT else None
        )
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–∞–ø –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        if GENERATE_TEXT_IN_PROMPT:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é
            response = requests.get(image_url)
            response.raise_for_status()
            image_with_text = BytesIO(response.content)
            image_with_text.seek(0)
        else:
            image_with_text = add_text_to_badge(image_url, badge_text, user_id)
        
        if BACKGROUND_REMOVAL_ENABLED:
            image_with_text = remove_background(image_with_text, user_id)
        
        await status_message.delete()
        original_scene = context.user_data.get('scene_original', scene_description_en)
        await update.message.reply_photo(
            photo=image_with_text,
            caption=MESSAGES["badge_ready_quick"].format(scene=original_scene, text=badge_text)
        )
    except ValueError as e:
        error_msg = str(e)
        logger.error(f"User {user_id}: Configuration error: {error_msg}")
        await status_message.edit_text(error_msg)
    except Exception as e:
        logger.error(f"User {user_id}: Failed to create badge: {e}")
        error_detail = str(e)
        
        if "404" in error_detail or "not found" in error_detail.lower():
            user_message = MESSAGES["errors"]["model_not_found"]
        elif "401" in error_detail or "unauthorized" in error_detail.lower():
            user_message = MESSAGES["errors"]["auth_error"]
        elif "429" in error_detail or "rate limit" in error_detail.lower():
            user_message = MESSAGES["errors"]["rate_limit"]
        else:
            user_message = MESSAGES["errors"]["generic_quick"].format(detail=error_detail)
        
        await status_message.edit_text(user_message)
    
    return ConversationHandler.END


# =============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# =============================================================================

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    if TELEGRAM_TOKEN == "YOUR_TELEGRAM_BOT_TOKEN":
        logger.error("‚ùå TELEGRAM_TOKEN not configured!")
        return
    
    if REPLICATE_API_TOKEN == "YOUR_REPLICATE_TOKEN":
        logger.error("‚ùå REPLICATE_API_TOKEN not configured!")
        return
    
    os.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_TOKEN
    
    logger.info("üöÄ Bot started successfully!")
    logger.info(f"üìä Using model: {GENERATION_MODEL}")
    
    if USE_PREDEFINED_REFERENCE_IMAGES:
        ref_images = load_reference_images_from_dir(REFERENCE_IMAGES_DIR)
        logger.info(f"üì∏ Predefined reference images: {len(ref_images)} image(s)")
    
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler("create", create_badge),
            CommandHandler("start", start),
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_quick_generate)
        ],
        states={
            WAITING_FOR_SCENE: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_scene_input)
            ],
            WAITING_FOR_REFERENCE_PHOTOS: [
                MessageHandler(filters.PHOTO, handle_reference_photos),
                CommandHandler("skip", skip_reference_photos)
            ],
            WAITING_FOR_BADGE_TEXT: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_badge_text_input)
            ],
        },
        fallbacks=[CommandHandler("cancel", cancel_command)],
    )
    
    application.add_handler(conv_handler)
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("examples", examples_command))
    
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
